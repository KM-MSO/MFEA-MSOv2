{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model import SMP_MFEA\n",
    "from MFEA_lib.model.utils import *\n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "from MFEA_lib.operators.Search import *\n",
    "from MFEA_lib.tasks.Benchmark.Competitions import CEC17_benchmark, GECCO20_benchmark_50tasks, WCCI22_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _updateProb(prob, k, dim_uss, nb_tasks, mean, std):\n",
    "    for i in range(nb_tasks):\n",
    "        for j in range(nb_tasks):\n",
    "            kl = np.log((std[i] + 1e-50)/(std[j] + 1e-50)) + (std[j] ** 2 + (mean[j] - mean[i]) ** 2)/(2 * std[i] ** 2 + 1e-50) - 1/2\n",
    "            # prob[i][j] = 1/(1 + kl/k)\n",
    "            prob[i][j] = np.exp(-kl/k)\n",
    "\n",
    "    return np.clip(prob, 1/dim_uss, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.4\n",
      "0.56.3\n",
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce GTX 1650'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-f3aef3b1-98ad-a6c1-74a1-210ce483e4ac\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "print(np.__version__)\n",
    "print(numba.__version__)\n",
    "\n",
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
      " 36. 38.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanminh/anaconda3/envs/lab/lib/python3.9/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/tanminh/anaconda3/envs/lab/lib/python3.9/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "# Example 1.1: Add scalars\n",
    "@cuda.jit\n",
    "def add_array(a, b, c):\n",
    "    i = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    if i < a.size:\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "N = 20\n",
    "a = np.arange(N, dtype=np.float32)\n",
    "b = np.arange(N, dtype=np.float32)\n",
    "dev_c = cuda.device_array_like(a)\n",
    "\n",
    "add_array[4, 8](a, b, dev_c)\n",
    "\n",
    "c = dev_c.copy_to_host()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#Y102sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m C \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#Y102sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m start \u001b[39m=\u001b[39m timer()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#Y102sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m matmul(A, B, C)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#Y102sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(timer() \u001b[39m-\u001b[39m start)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#Y102sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m start \u001b[39m=\u001b[39m timer() \n",
      "File \u001b[0;32m~/anaconda3/envs/lab/lib/python3.9/site-packages/numba/cuda/dispatcher.py:616\u001b[0m, in \u001b[0;36mCUDADispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    615\u001b[0m     \u001b[39m# An attempt to launch an unconfigured kernel\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(missing_launch_config_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: \nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "# @cuda.jit\n",
    "# def fast_matmul(A, B, C):\n",
    "#     # Define an array in the shared memory\n",
    "#     # The size and type of the arrays must be known at compile time\n",
    "#     sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "#     sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "#     x, y = cuda.grid(2)\n",
    "\n",
    "#     tx = cuda.threadIdx.x\n",
    "#     ty = cuda.threadIdx.y\n",
    "#     bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "#     if x >= C.shape[0] and y >= C.shape[1]:\n",
    "#         # Quit if (x, y) is outside of valid C boundary\n",
    "#         return\n",
    "\n",
    "#     # Each thread computes one element in the result matrix.\n",
    "#     # The dot product is chunked into dot products of TPB-long vectors.\n",
    "#     tmp = 0.\n",
    "#     for i in range(bpg):\n",
    "#         # Preload data into shared memory\n",
    "#         sA[tx, ty] = A[x, ty + i * TPB]\n",
    "#         sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "#         # Wait until all threads finish preloading\n",
    "#         cuda.syncthreads()\n",
    "\n",
    "#         # Computes partial product on the shared memory\n",
    "#         for j in range(TPB):\n",
    "#             tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "#         # Wait until all threads finish computing\n",
    "#         cuda.syncthreads()\n",
    "\n",
    "#     C[x, y] = tmp\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp\n",
    "\n",
    "from timeit import default_timer as timer  \n",
    "A = np.random.rand(100, 100)\n",
    "B = np.random.rand(100, 100)\n",
    "C = np.random.rand(100, 100)\n",
    "start = timer()\n",
    "matmul(A, B, C)\n",
    "print(timer() - start)\n",
    "\n",
    "start = timer() \n",
    "fast_matmul(A, B, C)\n",
    "print(timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "# def fast_matmul(A, B, C):\n",
    "#     # Define an array in the shared memory\n",
    "#     # The size and type of the arrays must be known at compile time\n",
    "#     sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "#     sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "#     x, y = cuda.grid(2)\n",
    "\n",
    "#     tx = cuda.threadIdx.x\n",
    "#     ty = cuda.threadIdx.y\n",
    "#     bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "#     if x >= C.shape[0] and y >= C.shape[1]:\n",
    "#         # Quit if (x, y) is outside of valid C boundary\n",
    "#         return\n",
    "\n",
    "#     # Each thread computes one element in the result matrix.\n",
    "#     # The dot product is chunked into dot products of TPB-long vectors.\n",
    "#     tmp = 0.\n",
    "#     for i in range(bpg):\n",
    "#         # Preload data into shared memory\n",
    "#         sA[tx, ty] = A[x, ty + i * TPB]\n",
    "#         sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "#         # Wait until all threads finish preloading\n",
    "#         cuda.syncthreads()\n",
    "\n",
    "#         # Computes partial product on the shared memory\n",
    "#         for j in range(TPB):\n",
    "#             tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "#         # Wait until all threads finish computing\n",
    "#         cuda.syncthreads()\n",
    "\n",
    "#     C[x, y] = tmp\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp\n",
    "\n",
    "from timeit import default_timer as timer  \n",
    "A = np.random.rand(100, 100)\n",
    "B = np.random.rand(100, 100)\n",
    "C = np.random.rand(100, 100)\n",
    "start = timer()\n",
    "matmul(A, B, C)\n",
    "print(timer() - start)\n",
    "\n",
    "start = timer() \n",
    "fast_matmul(A, B, C)\n",
    "print(timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ...\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STT: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 -- Time: 01m 3.93s  100 % [====================>]  Pop_size: 1.91E+03  ,  Cost: 2.54E+01  2.71E+01  3.87E+00  7.35E-02  3.48E+03  2.75E+00  3.24E+00  4.11E+01  2.14E-01  3.44E+02  ,  \n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "[99884, 100742, 100064, 100332, 99528, 99566, 100036, 99812, 101122, 99864]\n",
      "END!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STT: 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 1 -- Time: 00m 57.84s  100 % [====================>]  Pop_size: 1.91E+03  ,  Cost: 2.92E+01  2.83E+01  3.84E+00  7.09E-02  3.34E+03  2.81E+00  3.15E+00  5.65E+01  2.68E-01  3.37E+02  ,  \n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "[99944, 100184, 100356, 100484, 100268, 100030, 99252, 100130, 99988, 100314]\n",
      "END!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STT: 2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 2 -- Time: 00m 57.56s  100 % [====================>]  Pop_size: 1.91E+03  ,  Cost: 3.64E+01  2.52E+01  4.51E+00  1.00E-01  3.20E+03  3.11E+00  3.33E+00  5.29E+01  3.00E-01  3.52E+02  ,  \n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "[99530, 99918, 101306, 100414, 99852, 100538, 99882, 100014, 100204, 99292]\n",
      "END!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STT: 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 3 -- Time: 00m 44.48s   71 % [==============>     ]  Pop_size: 4.34E+03  ,  Cost: 1.07E+03  9.53E+02  7.59E+02  3.31E+00  1.11E+06  9.13E+00  2.05E+01  3.06E+03  1.20E+00  6.73E+02  ,  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiTimeModel.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.array(result[:][:min([len(his) for his in result])][:])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'model' object has no attribute 'last_pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiTimeModel.py:202\u001b[0m, in \u001b[0;36mMultiTimeModel.run\u001b[0;34m(self, nb_run, save_path, seed_arr, random_seed, replace_folder)\u001b[0m\n\u001b[1;32m    201\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_kwargs)\n\u001b[0;32m--> 202\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtime_end \u001b[39m-\u001b[39m model\u001b[39m.\u001b[39mtime_begin\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/SMP_MFEA.py:251\u001b[0m, in \u001b[0;36mmodel.fit\u001b[0;34m(self, nb_generations, nb_inds_each_task, nb_inds_min, lr, p_const_intra, prob_search, lc_nums, nb_epochs_stop, evaluate_initial_skillFactor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39m# add oa, ob to offsprings population and eval fcost\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m offsprings\u001b[39m.\u001b[39;49m__addIndividual__(oa)\n\u001b[1;32m    252\u001b[0m offsprings\u001b[39m.\u001b[39m__addIndividual__(ob)\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/EA.py:342\u001b[0m, in \u001b[0;36mPopulation.__addIndividual__\u001b[0;34m(self, individual, update_rank)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__addIndividual__\u001b[39m(\u001b[39mself\u001b[39m, individual:Individual, update_rank \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 342\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mls_subPop[individual\u001b[39m.\u001b[39;49mskill_factor]\u001b[39m.\u001b[39;49m__addIndividual__(individual, update_rank)\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/EA.py:143\u001b[0m, in \u001b[0;36mSubPopulation.__addIndividual__\u001b[0;34m(self, individual, update_rank)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m individual\u001b[39m.\u001b[39mfcost \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     individual\u001b[39m.\u001b[39mfcost \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask(individual\u001b[39m.\u001b[39;49mgenes)\n\u001b[1;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mls_inds\u001b[39m.\u001b[39mappend(individual)\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/tasks/Benchmark/Competitions/utils.py:212\u001b[0m, in \u001b[0;36mGriewank.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 212\u001b[0m     x \u001b[39m=\u001b[39m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49mdecode(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlimited_space, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrotation_matrix, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshift)\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m_func(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim)\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/tasks/Benchmark/Competitions/utils.py:58\u001b[0m, in \u001b[0;36mAbstractFunc.decode\u001b[0;34m(x, dim, limited_space, bound, rotation_matrix, shift)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m limited_space \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     x_decode \u001b[39m=\u001b[39m x_decode \u001b[39m*\u001b[39;49m (bound[\u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39;49m bound[\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39m bound[\u001b[39m0\u001b[39m]\n\u001b[1;32m     59\u001b[0m x_decode \u001b[39m=\u001b[39m rotation_matrix \u001b[39m@\u001b[39m (x_decode \u001b[39m-\u001b[39m shift) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m smpModel\u001b[39m.\u001b[39mcompile( \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     crossover \u001b[39m=\u001b[39m KL_SBXCrossover(nc\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, k\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m, conf_thres\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1e-12\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# crossover = SBX_Crossover(nc = 2),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     attr_tasks \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcrossover\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmutation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m smpModel\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     nb_generations\u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, nb_inds_each_task\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m, nb_inds_min\u001b[39m=\u001b[39m \u001b[39m200\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     lr \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m, p_const_intra\u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m, prob_search \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m, lc_nums \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     nb_epochs_stop\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m, swap_po\u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     evaluate_initial_skillFactor\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m a \u001b[39m=\u001b[39m smpModel\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     nb_run\u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,     \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     save_path\u001b[39m=\u001b[39;49m path\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiBenchmark.py:28\u001b[0m, in \u001b[0;36mMultiBenchmark.run\u001b[0;34m(self, nb_run, save_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_kwargs) \n\u001b[1;32m     27\u001b[0m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_kwargs) \n\u001b[0;32m---> 28\u001b[0m model\u001b[39m.\u001b[39;49mrun(nb_run \u001b[39m=\u001b[39;49m nb_run, save_path\u001b[39m=\u001b[39;49m save_path \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mls_name_benchmark[idx]) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.mso\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mls_model\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiTimeModel.py:210\u001b[0m, in \u001b[0;36mMultiTimeModel.run\u001b[0;34m(self, nb_run, save_path, seed_arr, random_seed, replace_folder)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRunning\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_attribute()\n\u001b[0;32m--> 210\u001b[0m save_result \u001b[39m=\u001b[39m saveModel(\u001b[39mself\u001b[39;49m, save_path)\n\u001b[1;32m    211\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mKeyboardInterrupt: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    212\u001b[0m       save_result \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m model, model is not Done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    213\u001b[0m traceback\u001b[39m.\u001b[39mprint_exc()\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiTimeModel.py:252\u001b[0m, in \u001b[0;36msaveModel\u001b[0;34m(model, PATH, remove_tasks)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mfor\u001b[39;00m submodel \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mls_model:\n\u001b[1;32m    251\u001b[0m     submodel\u001b[39m.\u001b[39mtasks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     submodel\u001b[39m.\u001b[39;49mlast_pop\u001b[39m.\u001b[39mls_tasks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39mfor\u001b[39;00m subpop \u001b[39min\u001b[39;00m submodel\u001b[39m.\u001b[39mlast_pop:\n\u001b[1;32m    254\u001b[0m         subpop\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'model' object has no attribute 'last_pop'"
     ]
    }
   ],
   "source": [
    "# cec17\n",
    "t, ic = CEC17_benchmark.get_10tasks_benchmark()\n",
    "\n",
    "ls_benchmark = [t]\n",
    "ls_IndClass = [ic]\n",
    "name_benchmark = [\"cec17\"]\n",
    "path = './RESULTS/result/CEC17/SMP_v2/'\n",
    "\n",
    "smpModel = MultiBenchmark(\n",
    "    ls_benchmark= ls_benchmark,\n",
    "    name_benchmark= name_benchmark,\n",
    "    ls_IndClass= ls_IndClass,\n",
    "    model= SMP_MFEA\n",
    ")\n",
    "smpModel.compile( \n",
    "    crossover = KL_SBXCrossover(nc= 2, k= 1000, conf_thres= 1 - 1e-12),\n",
    "    # crossover = SBX_Crossover(nc = 2),\n",
    "    mutation = PolynomialMutation(nm = 5, pm= 1),\n",
    "    selection= ElitismSelection(random_percent= 0.1),\n",
    "    search= L_SHADE(len_mem= 15),\n",
    "    attr_tasks = ['crossover', 'mutation', 'search'],\n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 100, nb_inds_each_task= 1000, nb_inds_min= 200,\n",
    "    lr = 0.1, p_const_intra= 0., prob_search = 0., lc_nums = 200,\n",
    "    nb_epochs_stop= 1000, swap_po= False,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "a = smpModel.run(\n",
    "    nb_run= 5,     \n",
    "    save_path= path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './RESULTS/result/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_1.mso'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/tanminh/New%20Volume/LinhTinh/Code_Lab/MFEA-MSOv2/7_multi_run.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model21 \u001b[39m=\u001b[39m loadModel(\u001b[39m\"\u001b[39;49m\u001b[39m./RESULTS/result/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_1.mso\u001b[39;49m\u001b[39m\"\u001b[39;49m, ls_tasks\u001b[39m=\u001b[39;49mWCCI22_benchmark\u001b[39m.\u001b[39;49mget_50tasks_benchmark(\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m/media/tanminh/New Volume/LinhTinh/Code_Lab/MFEA-MSOv2/MFEA_lib/model/utils/MultiTimeModel.py:336\u001b[0m, in \u001b[0;36mloadModel\u001b[0;34m(PATH, ls_tasks, set_attribute)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[39massert\u001b[39;00m path_tmp\u001b[39m.\u001b[39mname[i:] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mso\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOnly load model with .mso, not \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[1;32m    334\u001b[0m         path_tmp\u001b[39m.\u001b[39mname[i:]\n\u001b[0;32m--> 336\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(PATH, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    337\u001b[0m model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    338\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './RESULTS/result/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_1.mso'"
     ]
    }
   ],
   "source": [
    "model21 = loadModel(\"./RESULTS/result/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_1.mso\", ls_tasks=WCCI22_benchmark.get_50tasks_benchmark(1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model21.history_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"./RESULTS/result/GECCO20/LSA_2022/1.mso\", ls_tasks=WCCI22_benchmark.get_50tasks_benchmark(1)[0])\n",
    "model.set_attribute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.history_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model import AbstractModel, SMP_MFEA, MFEA_base, SMP_DE, LSA21\n",
    "from MFEA_lib.model.utils import *\n",
    "from MFEA_lib.model.utils import TuningModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from MFEA_lib.tasks.Benchmark.Funcs import * \n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "from MFEA_lib.operators.Search import *\n",
    "\n",
    "ls_benchmark = []\n",
    "ls_IndClass = []\n",
    "ls_tasks = [1,2,3,4,5,6,7,8,9,10]\n",
    "name_benchmark = [] \n",
    "\n",
    "for i in ls_tasks:\n",
    "    t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "    ls_benchmark.append(t)\n",
    "    ls_IndClass.append(ic)\n",
    "    name_benchmark.append(str(i))\n",
    "\n",
    "\n",
    "\n",
    "smpModel = MultiBenchmark(\n",
    "    ls_benchmark= ls_benchmark,\n",
    "    name_benchmark= name_benchmark,\n",
    "    ls_IndClass= ls_IndClass,\n",
    "    model= LSA21\n",
    ")\n",
    "\n",
    "smpModel.compile(\n",
    "    # crossover= newSBX(nc = 2, gamma= 0.6, alpha = 7),\n",
    "    # crossover = SBX_LSA21(),\n",
    "    # crossover = KL_SBX(nc= 2, k= 7),\n",
    "    crossover= KL_SBX_LSA21(nc=2, k=7),\n",
    "    # crossover = SBX_Crossover(nc=5),\n",
    "    # mutation= GaussMutation(scale= 0.1),\n",
    "    mutation = PolynomialMutation(pm=1, nm=7),\n",
    "    # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    search = LSHADE_LSA21(len_mem=30, p_ontop=0.11),\n",
    "    attr_tasks = ['crossover', 'mutation', 'search'],\n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 1000, nb_inds_each_task= 100, nb_inds_min= 4,\n",
    "    lr = 0.1\n",
    ")\n",
    "a = smpModel.run(\n",
    "    nb_run= 2,\n",
    "    save_path= './RESULTS/result/WCCI22_complex/SMP_v2/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = CompareResultBenchmark(path_folder=\"./RESULTS/result/GECCO20\", ls_benchmark=[WCCI22_benchmark.get_50tasks_benchmark(i)[0] for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.summarizing_compare_result(idx_main_algo=1, min_value=1e-6, idx_gener_compare=-1, total_generation=1000, combine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.show_compare_detail(idx_main_algo=1, min_value=1e-6, round=7,idx_gener_compare=-1, total_generation=1000) \n",
    "# idx_gener_compare : vị trí thế hệ mà tại đó muốn so sánh các thuật toán với nhau\n",
    "# total generation : số thế hệ của thuật toán. mặc định là 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare2 = CompareResultBenchmark(path_folder=\"./RESULTS/result/WCCI22_complex\", ls_benchmark=[WCCI22_benchmark.get_complex_benchmark(i)[0] for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare2.summarizing_compare_result(idx_main_algo=0, min_value=1e-6, idx_gener_compare=-1, total_generation=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare2.show_compare_detail(idx_main_algo=1, min_value=1e-6, round=7,idx_gener_compare=-1, total_generation=1000) \n",
    "# idx_gener_compare : vị trí thế hệ mà tại đó muốn so sánh các thuật toán với nhau\n",
    "# total generation : số thế hệ của thuật toán. mặc định là 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = [] \n",
    "ls_IndClass = [] \n",
    "name_benchmarks = []\n",
    "for id in range(1, 11): \n",
    "    # b, i = WCCI22_benchmark.get_50tasks_benchmark(id) \n",
    "    b, i = WCCI22_benchmark.get_complex_benchmark(id) \n",
    "    name_benchmarks.append(\"50tasks_id_\" + str(id))\n",
    "    ls_benchmark.append(b) \n",
    "    ls_IndClass.append(i) \n",
    "\n",
    "benchmark_weights = np.array([1,1,1,1,1,1,1,1,1.0,1.0])\n",
    "benchmark_weights /= np.sum(benchmark_weights)\n",
    "benchmark_weights = benchmark_weights.tolist()\n",
    "\n",
    "model = TuningModel(\n",
    "    model_name= SMP_MFEA, \n",
    "    list_parameter= [\n",
    "        # ('mutation', {\n",
    "        #     'pm': [1, 1.5, 0.75],\n",
    "        #     'nm': [5,7],\n",
    "        # }),\n",
    "\n",
    "        # ('lr', [0.05, 0.1,0.15]),\n",
    "        ('prob_search', [1, 0.75, 0.5]),\n",
    "        # ('nb_inds_min', [100, 50, 25])\n",
    "    ],\n",
    ")\n",
    "model.compile(\n",
    "    ls_benchmark = ls_benchmark, \n",
    "    benchmark_weights = benchmark_weights, \n",
    "    name_benchmark = name_benchmarks,\n",
    "    ls_IndClass = ls_IndClass,\n",
    "\n",
    "    # tasks = None,\n",
    "    # IndClass= None,\n",
    "    # tasks = CEC17_benchmark.get_10tasks_benchmark(),\n",
    "    crossover= newSBX(nc = 2, gamma= 0.4, alpha = 6),\n",
    "    # crossover= SBX_Crossover(nc = 2),\n",
    "    # mutation = GaussMutation(scale = 0.01),\n",
    "    mutation = PolynomialMutation(nm=5, pm= 1),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    search= SHADE(len_mem= 6, p_ontop= 0.1), \n",
    "    attr_tasks = ['crossover', 'mutation', 'search']\n",
    ")\n",
    "\n",
    "fit, com, result = model.run(\n",
    "    path=\"./RESULTS/tuning_50/\",\n",
    "    replace_folder=True,\n",
    "    min_value = 1e-6,\n",
    "    \n",
    "    nb_generations= 5, \n",
    "    nb_inds_each_task= 100, \n",
    "    nb_inds_min= 30,\n",
    "    lr = 0.1,  \n",
    "    p_const_intra= 0,  \n",
    "    prob_search = 1.0,\n",
    "    nb_epochs_stop= 1000, \n",
    "    swap_po= False,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = [] \n",
    "ls_IndClass = [] \n",
    "for id in range(1, 3): \n",
    "    b, i = CEC17_benchmark.get_2tasks_benchmark(id) \n",
    "    ls_benchmark.append(b) \n",
    "    ls_IndClass.append(i) \n",
    "\n",
    "b, i = CEC17_benchmark.get_10tasks_benchmark() \n",
    "ls_benchmark.append(b)\n",
    "ls_IndClass.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TuningModel(\n",
    "    model_name= SMP_MFEA, \n",
    "    list_parameter= [\n",
    "        ('crossover', {\n",
    "            'gamma': [0.4, 0.6]\n",
    "        }), \n",
    "        ('lr', [0.04, 0.05]),\n",
    "        ('crossover', {\n",
    "            'alpha': [5, 7]\n",
    "        }), \n",
    "    ],\n",
    ")\n",
    "model.compile(\n",
    "    ls_benchmark = ls_benchmark, \n",
    "    benchmark_weights = (np.ones(shape= (3,)) / 3).tolist(), \n",
    "    name_benchmark = [str(i) for i in range(1,4)],\n",
    "    ls_IndClass = ls_IndClass,\n",
    "\n",
    "    # tasks = None,\n",
    "    # IndClass= None,\n",
    "    # tasks = CEC17_benchmark.get_10tasks_benchmark(),\n",
    "    crossover= newSBX(nc = 2, gamma= 0.4, alpha = 6),\n",
    "    # crossover= SBX_Crossover(nc = 2),\n",
    "    mutation = GaussMutation(scale = 0.01),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    # search= SHADE(len_mem= 30, p_ontop= 0.1), \n",
    "    attr_tasks = ['crossover', 'mutation']\n",
    ")\n",
    "\n",
    "fit, com, result = model.run(\n",
    "    replace_folder=True,\n",
    "    min_value = 1e-6,\n",
    "    \n",
    "    nb_generations= 5, \n",
    "    nb_inds_each_task= 100, \n",
    "    nb_inds_min= 100,\n",
    "    lr = 0.05,  \n",
    "    p_const_intra= 0, \n",
    "    p_mutate= 0.1, \n",
    "    prob_search = 0.,\n",
    "    nb_epochs_stop= 1000, \n",
    "    swap_po= False,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show and compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(1, 11): \n",
    "    SMP = loadModel(\"./RESULTS/__static__/GECCO20/SMP_NEWSBX_TUN_50/Gecco_id_\"+ str(id) + \".mso\", GECCO20_benchmark_50tasks.get_items(id)[0])\n",
    "    SA = loadModel(\"./RESULTS/__static__/GECCO20/SA/SA_Benchmark_\"+str(id) + \".mso\", GECCO20_benchmark_50tasks.get_items(id)[0])\n",
    "    LSA_21 = loadModel(\"./RESULTS/__static__/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_\"+str(id) + \".mso\", GECCO20_benchmark_50tasks.get_items(id)[0])\n",
    "    com = CompareModel([SMP, SA, LSA_21])\n",
    "    print(com.detail_compare_result(min_value= 1e-6, round = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFEA_model = loadModel('./RESULTS/MFEA_cec17.mso')\n",
    "EBS_GA_model = loadModel('./RESULTS/EBS_GA_cec17.mso')\n",
    "MaTDE_model = loadModel('./RESULTS/MaTDE_cec17.mso')\n",
    "MaTGA_model = loadModel('./RESULTS/MaTGA_cec17.mso')\n",
    "MTEA_AD_model = loadModel('./RESULTS/MTEA_AD_cec17.mso')\n",
    "SA_model = loadModel('./RESULTS/SA_cec17.mso')\n",
    "LSA_model = loadModel('./RESULTS/LSA_cec17.mso')\n",
    "# SMP_NEWSBX = loadModel(\"./RESULTS/SMP_NEWSBX.mso\", ls_tasks= CEC17_benchmark.get_10tasks_benchmark())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = CompareModel(\n",
    "    models = [MFEA_model, EBS_GA_model, MaTDE_model, MaTGA_model, MTEA_AD_model, SA_model, LSA_model],\n",
    "    label= [...] * 7 ,\n",
    ")\n",
    "# compare.render(    \n",
    "#     shape = (2, 5),\n",
    "#     min_cost= 0,\n",
    "#     step= 100,\n",
    "#     yscale= 'log'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.detail_compare_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.summarizing_compare_result(path=None , idx_main_algo= 2, nb_task= 2, ls_benchmark= [CEC17_benchmark.get_2tasks_benchmark(id) for id in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"./RESULTS/50tasks/SMP_NEWSBX/lan2_2s_newsbx_50task_1.mso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.summarizing_compare_result(path=\"./RESULTS/complex_2tasks/\", idx_main_algo= 0, nb_task= 2, ls_benchmark= [WCCI22_benchmark.get_complex_benchmark(id)[0] for id in range(1,10)],min_value= 1e-6, combine= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.summarizing_compare_result(path=\"./RESULTS/50tasks/\", idx_main_algo= 7, nb_task= 50, ls_benchmark= [GECCO20_benchmark_50tasks.get_items(id) for id in range(1,11)],min_value= 1e-6, combine= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Time Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(4, 11): \n",
    "    tasks, IndClass= WCCI22_benchmark.get_50tasks_benchmark(id)\n",
    "\n",
    "    smpModel = MultiTimeModel(model= SMP_MFEA)\n",
    "    smpModel.compile(\n",
    "        tasks= tasks,\n",
    "        IndClass = IndClass,\n",
    "        crossover= newSBX(nc = 2, gamma= 0.4, alpha = 6),\n",
    "        mutation= GaussMutation(scale= 0.1),\n",
    "        # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "        selection= ElitismSelection(random_percent= 0.),\n",
    "        attr_tasks = ['crossover', 'mutation'],\n",
    "        \n",
    "    )\n",
    "    smpModel.fit(\n",
    "        nb_generations= 1000, nb_inds_each_task= 100, nb_inds_min= 30,\n",
    "        lr = 0.15, p_const_intra= 0.0, p_mutate= 0.1,prob_search = 0.0,\n",
    "        nb_epochs_stop= 1500, \n",
    "        evaluate_initial_skillFactor= True\n",
    "    )\n",
    "    smpModel.run(\n",
    "        nb_run= 1,\n",
    "        save_path= './RESULTS/results/smpv2_50tasks_id_'+ str(id) + '.mso'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(1, 11): \n",
    "    tasks, IndClass= WCCI22_benchmark.get_50tasks_benchmark(id)\n",
    "\n",
    "    smpModel = MultiTimeModel(model= SMP_MFEA)\n",
    "    smpModel.compile(\n",
    "        tasks= tasks,\n",
    "        IndClass = IndClass,\n",
    "        crossover= newSBX(nc = 2, gamma= 0.4, alpha = 6),\n",
    "        mutation= GaussMutation(scale= 0.1),\n",
    "        # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "        selection= ElitismSelection(random_percent= 0.),\n",
    "        attr_tasks = ['crossover', 'mutation'],\n",
    "        \n",
    "    )\n",
    "    smpModel.fit(\n",
    "        nb_generations= 1000, nb_inds_each_task= 100, nb_inds_min= 30,\n",
    "        lr = 0.15, p_const_intra= 0.0, p_mutate= 0.1,prob_search = 0.0,\n",
    "        nb_epochs_stop= 1500, \n",
    "        evaluate_initial_skillFactor= True\n",
    "    )\n",
    "    smpModel.run(\n",
    "        nb_run= 5,\n",
    "        save_path= './RESULTS/result/WCCI22_50tasks_id_'+ str(id) + '.mso'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, IndClass= CEC17_benchmark.get_10tasks_benchmark()\n",
    "\n",
    "smpModel = MultiTimeModel(model= SMP_MFEA)\n",
    "smpModel.compile(\n",
    "    tasks= tasks,\n",
    "    IndClass = IndClass,\n",
    "    crossover= newSBX(nc = 2, gamma= 0.4, alpha = 6),\n",
    "    mutation= GaussMutation(scale= 0.1),\n",
    "    # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    search = SHADE(),\n",
    "    attr_tasks = ['crossover', 'mutation'],\n",
    "    \n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 10, nb_inds_each_task= 100, nb_inds_min= 30,\n",
    "    lr = 0.15, p_const_intra= 0.0, p_mutate= 0.1,prob_search = 0.0,\n",
    "    nb_epochs_stop= 1500, \n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "smpModel.run(\n",
    "    nb_run= 1,\n",
    "    save_path= './RESULTS/result/MFEA_cec17_final.mso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpModel.render_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpModel.print_result(['history_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = [] \n",
    "ls_IndClass = [] \n",
    "for id in range(1, 10): \n",
    "    b, i = CEC17_benchmark.get_2tasks_benchmark(id) \n",
    "    ls_benchmark.append(b) \n",
    "    ls_IndClass.append(i) \n",
    "\n",
    "b, i = CEC17_benchmark.get_10tasks_benchmark() \n",
    "ls_benchmark.append(b)\n",
    "ls_IndClass.append(i)\n",
    "\n",
    "smpModel = MultiBenchmark(\n",
    "    ls_benchmark = ls_benchmark, \n",
    "    name_benchmark = [str(i) for i in range(1,4)],\n",
    "    ls_IndClass = ls_IndClass,\n",
    "    model= SMP_MFEA\n",
    "    )\n",
    "\n",
    "smpModel.compile(\n",
    "    crossover= newSBX(nc = 2, gamma= 0.6, alpha = 7),\n",
    "    mutation= GaussMutation(scale= 0.1),\n",
    "    # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    attr_tasks = ['crossover', 'mutation'],\n",
    "    \n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 10, nb_inds_each_task= 100, nb_inds_min= 100,\n",
    "    lr = 0.1, p_const_intra= 0.0, p_mutate= 0.1,prob_search = 0.0,\n",
    "    nb_epochs_stop= 50, \n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "smpModel.run(\n",
    "    nb_run= 2,\n",
    "    save_path= './RESULTS/result/smpMFEA_cec17.mso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpModel.print_result(['history_cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMP DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, IndClass= WCCI22_benchmark.get_complex_benchmark(3)\n",
    "\n",
    "smpModel = MultiTimeModel(model= SMP_MFEA)\n",
    "smpModel.compile(\n",
    "    tasks= tasks,\n",
    "    IndClass = IndClass,\n",
    "    crossover= newSBX(nc = 2, gamma= 0.6, alpha = 7),\n",
    "    # crossover = SBX_Crossover(nc=5),\n",
    "    # mutation= GaussMutation(scale= 0.1),\n",
    "    mutation = PolynomialMutation(pm=1, nm=7),\n",
    "    # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    search = L_SHADE(len_mem=6, p_ontop=0.1),\n",
    "    attr_tasks = ['crossover', 'mutation', 'search'],\n",
    "    \n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 1000, nb_inds_each_task= 100, nb_inds_min= 30,\n",
    "    lr = 0.1, p_const_intra= 0.0, p_mutate= 0.1,prob_search = 1.0,\n",
    "    nb_epochs_stop= 1, \n",
    "    evaluate_initial_skillFactor= True, step_over= 5,\n",
    ")\n",
    "smpModel.run(\n",
    "    nb_run= 1,\n",
    "    save_path= './RESULTS/result/smpMFEA_cec17.mso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpModel.render_smp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_21 = loadModel(\"./RESULTS/__static__/GECCO20/LSA_2021/LSA_2021_MTOMSO_Benchmark_8.mso\",WCCI22_benchmark.get_50tasks_benchmark(8)[0])\n",
    "model = loadModel('./RESULTS/result/smpMFEA_cec17.mso', WCCI22_benchmark.get_50tasks_benchmark(8)[0])\n",
    "\n",
    "compare = CompareModel([lsa_21, model])\n",
    "compare.detail_compare_result(min_value=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMP - LSHADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = []\n",
    "ls_IndClass = []\n",
    "\n",
    "for i in range(1, 2, 1):\n",
    "    t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "    ls_benchmark.append(t)\n",
    "    ls_IndClass.append(ic)\n",
    "\n",
    "name_benchmark = np.arange(len(ls_benchmark)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = []\n",
    "ls_IndClass = []\n",
    "\n",
    "for i in range(1, 3, 1):\n",
    "    t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "    ls_benchmark.append(t)\n",
    "    ls_IndClass.append(ic)\n",
    "\n",
    "name_benchmark = np.arange(len(ls_benchmark)) + 1\n",
    "\n",
    "\n",
    "smpModel = MultiBenchmark(\n",
    "    ls_benchmark= ls_benchmark,\n",
    "    name_benchmark= name_benchmark,\n",
    "    ls_IndClass= ls_IndClass,\n",
    "    model= SMP_MFEA\n",
    ")\n",
    "\n",
    "smpModel.compile(\n",
    "    crossover= newSBX(nc = 2, gamma= 0.6, alpha = 7),\n",
    "    # crossover = SBX_Crossover(nc=5),\n",
    "    # mutation= GaussMutation(scale= 0.1),\n",
    "    mutation = PolynomialMutation(pm=1, nm=7),\n",
    "    # mutation = GMMScale(alpha = 3, lenMem= 20, default_scale= 0.5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    "    search = L_SHADE(len_mem=6, p_ontop=0.1),\n",
    "    attr_tasks = ['crossover', 'mutation', 'search'],\n",
    ")\n",
    "smpModel.fit(\n",
    "    nb_generations= 5, nb_inds_each_task= 100, nb_inds_min= 30,\n",
    "    lr = 0.1, p_const_intra= 0.0, prob_search = 1.0,\n",
    "    nb_epochs_stop= 1000, swap_po= False,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "a = smpModel.run(\n",
    "    nb_run= 1,\n",
    "    save_path= './RESULTS/result/WCCI22_complex/SMP_v2/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"./RESULTS/result/WCCI22_complex/SMP_v2/1.mso\", ls_tasks=WCCI22_benchmark.get_complex_benchmark(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history_cost[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = CompareResultBenchmark(\n",
    "    path_folder= \"./RESULTS/result/WCCI22_complex\",\n",
    "    ls_benchmark= [WCCI22_benchmark.get_complex_benchmark(i)[0] for i in range(1, 10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.summarizing_compare_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.show_compare_detail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec2b8e3cf2de477d6f7eee5b7012c6c41c5b0a3316c750e923bfb234960f6078"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
